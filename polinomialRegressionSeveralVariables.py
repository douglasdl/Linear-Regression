# ğ‘“(ğ‘¥â‚, ğ‘¥â‚‚) = ğ‘â‚€ + ğ‘â‚ğ‘¥â‚ + ğ‘â‚‚ğ‘¥â‚‚ + ğ‘â‚ƒğ‘¥â‚Â² + ğ‘â‚„ğ‘¥â‚ğ‘¥â‚‚ + ğ‘â‚…ğ‘¥â‚‚Â²
# https://realpython.com/linear-regression-in-python/

# Import packages and classes
import numpy as np
from sklearn.linear_model import LinearRegression
from sklearn.preprocessing import PolynomialFeatures

isDebugMode = True

# Provide data (x, y)
# input = regressor: x
x = [[0, 1], [5, 1], [15, 2], [25, 5], [35, 11], [45, 15], [55, 34], [60, 35]]
x = np.array(x)
print("x") if isDebugMode else ""
print(x) if isDebugMode else ""

# output = predictor: y
y = [4, 5, 20, 14, 32, 22, 38, 43]
y = np.array(y)
print("y") if isDebugMode else ""
print(y) if isDebugMode else ""

# Transform input data
transformer = PolynomialFeatures(degree=2, include_bias=False)
transformer.fit(x)

# 1st column is the original x and the 2nd column is ğ‘¥Â²
x_ = transformer.transform(x)
print(x_)

# Create a regression model
model = LinearRegression()

# Fit the model with existing data
model.fit(x_, y)

# Get the results (ğ‘…Â²) of the model fitting
r_sq = model.score(x_, y)
print('coefficient of determination:', r_sq)

# ğ‘â‚€
print('intercept:', model.intercept_)

# ğ‘â‚, ğ‘â‚‚, ğ‘â‚ƒ, ğ‘â‚„ and ğ‘â‚…
print('coefficients:', model.coef_)

# Apply the model for predictions (y = ğ‘â‚€ + ğ‘â‚ğ‘¥â‚ + ğ‘â‚‚ğ‘¥â‚‚ + ğ‘â‚ƒğ‘¥â‚Â² + ğ‘â‚„ğ‘¥â‚ğ‘¥â‚‚ + ğ‘â‚…ğ‘¥â‚‚Â²)
# y_pred = model.intercept_ + model.coef_ * x
y_pred = model.predict(x_)
print('predicted response:', y_pred, sep='\n')